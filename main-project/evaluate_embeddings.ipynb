{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "l2p7tLHeSFVK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Merged rows: 2582\n",
            "# embedding dims: 768\n",
            "\n",
            "task_any_dr value_counts:\n",
            "task_any_dr\n",
            "0    2001\n",
            "1     581\n",
            "Name: count, dtype: Int64\n",
            "\n",
            "task_referable value_counts:\n",
            "task_referable\n",
            "0    2131\n",
            "1     451\n",
            "Name: count, dtype: Int64\n",
            "\n",
            "task_3class value_counts:\n",
            "task_3class\n",
            "0       1856\n",
            "1        478\n",
            "2        103\n",
            "<NA>     145\n",
            "Name: count, dtype: Int64\n",
            "\n",
            "sex value_counts:\n",
            "sex\n",
            "0    1680\n",
            "1     902\n",
            "Name: count, dtype: int64\n",
            "\n",
            "X shape: (2582, 768)\n",
            "\n",
            "Task: task_any_dr\n",
            "test n: 516 pos rate: 0.23062015503875968\n",
            "accuracy: 0.405 f1: 0.4107\n",
            "\n",
            "Task: task_referable\n",
            "test n: 516 pos rate: 0.18410852713178294\n",
            "accuracy: 0.3992 f1: 0.3595\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import importlib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import src.retina_embeddings_dataset as red\n",
        "\n",
        "# Ensure the notebook uses the latest loader code without needing a kernel restart.\n",
        "importlib.reload(red)\n",
        "load_retina_embeddings_dataset = red.load_retina_embeddings_dataset\n",
        "select_feature_matrix = red.select_feature_matrix\n",
        "\n",
        "# --- Config (pick ONE dataset + ONE embeddings file) ---\n",
        "ROOT = Path.cwd()  # expected: .../Sprint-Project-4-5/Solved\n",
        "\n",
        "DATASET = \"mbrset\"  # \"mbrset\" or \"brset\"\n",
        "\n",
        "if DATASET == \"mbrset\":\n",
        "    EMBEDDINGS_CSV = ROOT / \"data\" / \"mbrset_embeddings\" / \"Embeddings_vit_base_mbrset.csv\"\n",
        "    LABELS_CSV = ROOT / \"data\" / \"mbrset_embeddings\" / \"mbrset_labels\" / \"labels_mbrset.csv\"\n",
        "    VIEW = \"macula\"  # \"macula\" keeps .1/.3 images; \"all\" keeps everything\n",
        "else:\n",
        "    EMBEDDINGS_CSV = ROOT / \"data\" / \"brset_embeddings\" / \"Embeddings_brset_vit_base_.csv\"\n",
        "    LABELS_CSV = ROOT / \"data\" / \"brset_embeddings\" / \"brset_labels\" / \"labels_brset.csv\"\n",
        "    VIEW = \"all\"\n",
        "\n",
        "# --- Load + merge embeddings with labels; derive tasks ---\n",
        "ds = load_retina_embeddings_dataset(\n",
        "    dataset=DATASET,\n",
        "    embeddings_csv_path=str(EMBEDDINGS_CSV),\n",
        "    labels_csv_path=str(LABELS_CSV),\n",
        "    view=VIEW,\n",
        ")\n",
        "\n",
        "df = ds.df\n",
        "print(\"Merged rows:\", len(df))\n",
        "print(\"# embedding dims:\", len(ds.feature_cols))\n",
        "\n",
        "# --- Task distributions (clinical + privacy targets) ---\n",
        "cols_to_show = [\n",
        "    \"task_any_dr\",\n",
        "    \"task_referable\",\n",
        "    \"task_3class\",\n",
        "    \"sex\",\n",
        "]\n",
        "\n",
        "for c in cols_to_show:\n",
        "    if c in df.columns:\n",
        "        vc = df[c].value_counts(dropna=False).sort_index()\n",
        "        print(f\"\\n{c} value_counts:\\n{vc}\")\n",
        "\n",
        "# --- Feature matrix ---\n",
        "X = select_feature_matrix(df, ds.feature_cols)\n",
        "print(\"\\nX shape:\", X.shape)\n",
        "\n",
        "# --- Minimal (numpy-only) baseline: ridge regression classifier ---\n",
        "\n",
        "def _train_test_split_by_patient(\n",
        "    df_in: pd.DataFrame,\n",
        "    patient_col: str,\n",
        "    test_size: float = 0.2,\n",
        "    seed: int = 0,\n",
        ") -> tuple[np.ndarray, np.ndarray]:\n",
        "    rng = np.random.default_rng(seed)\n",
        "    patients = df_in[patient_col].dropna().astype(str).unique().tolist()\n",
        "    patients = np.array(patients, dtype=object)\n",
        "    rng.shuffle(patients)\n",
        "\n",
        "    n_test = max(1, int(round(len(patients) * test_size)))\n",
        "    test_patients = set(patients[:n_test].tolist())\n",
        "\n",
        "    patient_vals = df_in[patient_col].astype(str).to_numpy()\n",
        "    test_mask = np.array([p in test_patients for p in patient_vals], dtype=bool)\n",
        "    train_mask = ~test_mask\n",
        "    return train_mask, test_mask\n",
        "\n",
        "\n",
        "def _standardize_fit(X_train: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
        "    mean = X_train.mean(axis=0)\n",
        "    std = X_train.std(axis=0)\n",
        "    std[std == 0] = 1.0\n",
        "    return mean, std\n",
        "\n",
        "\n",
        "def _standardize_apply(X_in: np.ndarray, mean: np.ndarray, std: np.ndarray) -> np.ndarray:\n",
        "    return (X_in - mean) / std\n",
        "\n",
        "\n",
        "def _ridge_fit(X_train: np.ndarray, y_train: np.ndarray, alpha: float = 1.0) -> np.ndarray:\n",
        "    # Adds bias term.\n",
        "    Xb = np.hstack([X_train, np.ones((X_train.shape[0], 1), dtype=X_train.dtype)])\n",
        "    # Closed-form: w = (X^T X + a I)^-1 X^T y\n",
        "    d = Xb.shape[1]\n",
        "    A = Xb.T @ Xb + alpha * np.eye(d, dtype=Xb.dtype)\n",
        "    b = Xb.T @ y_train\n",
        "    w = np.linalg.solve(A, b)\n",
        "    return w\n",
        "\n",
        "\n",
        "def _ridge_predict_proba(X_in: np.ndarray, w: np.ndarray) -> np.ndarray:\n",
        "    Xb = np.hstack([X_in, np.ones((X_in.shape[0], 1), dtype=X_in.dtype)])\n",
        "    logits = Xb @ w\n",
        "    # sigmoid\n",
        "    return 1.0 / (1.0 + np.exp(-logits))\n",
        "\n",
        "\n",
        "def _f1_binary(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
        "    tp = int(((y_true == 1) & (y_pred == 1)).sum())\n",
        "    fp = int(((y_true == 0) & (y_pred == 1)).sum())\n",
        "    fn = int(((y_true == 1) & (y_pred == 0)).sum())\n",
        "    if tp == 0:\n",
        "        return 0.0\n",
        "    precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
        "    recall = tp / (tp + fn) if (tp + fn) else 0.0\n",
        "    if (precision + recall) == 0:\n",
        "        return 0.0\n",
        "    return 2 * precision * recall / (precision + recall)\n",
        "\n",
        "\n",
        "def run_binary_task(task_col: str, patient_col: str = \"patient_id\") -> None:\n",
        "    if task_col not in df.columns:\n",
        "        print(f\"\\n[skip] Missing column: {task_col}\")\n",
        "        return\n",
        "    if patient_col not in df.columns:\n",
        "        print(f\"\\n[skip] Missing patient column: {patient_col}\")\n",
        "        return\n",
        "\n",
        "    task_df = df.dropna(subset=[task_col]).copy()\n",
        "    y = task_df[task_col].astype(int).to_numpy()\n",
        "    X_task = select_feature_matrix(task_df, ds.feature_cols)\n",
        "\n",
        "    train_mask, test_mask = _train_test_split_by_patient(task_df, patient_col=patient_col, seed=0)\n",
        "    X_train, X_test = X_task[train_mask], X_task[test_mask]\n",
        "    y_train, y_test = y[train_mask], y[test_mask]\n",
        "\n",
        "    mean, std = _standardize_fit(X_train)\n",
        "    X_train_s = _standardize_apply(X_train, mean, std)\n",
        "    X_test_s = _standardize_apply(X_test, mean, std)\n",
        "\n",
        "    w = _ridge_fit(X_train_s, y_train.astype(np.float32), alpha=10.0)\n",
        "    p = _ridge_predict_proba(X_test_s, w)\n",
        "    y_pred = (p >= 0.5).astype(int)\n",
        "\n",
        "    acc = float((y_pred == y_test).mean())\n",
        "    f1 = _f1_binary(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nTask: {task_col}\")\n",
        "    print(\"test n:\", len(y_test), \"pos rate:\", float(y_test.mean()) if len(y_test) else None)\n",
        "    print(\"accuracy:\", round(acc, 4), \"f1:\", round(f1, 4))\n",
        "\n",
        "\n",
        "run_binary_task(\"task_any_dr\")\n",
        "run_binary_task(\"task_referable\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m all_oof = []\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m TASKS:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     res = \u001b[43mreval\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate_binary_models_groupkfold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroup_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpatient_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODELS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     s = res.summary.copy()\n\u001b[32m     26\u001b[39m     s.insert(\u001b[32m0\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtask\u001b[39m\u001b[33m\"\u001b[39m, task)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Julian\\OneDrive\\Desktop\\testing-retina-project\\Sprint-Project-4-5\\Solved\\src\\retina_evaluation.py:196\u001b[39m, in \u001b[36mevaluate_binary_models_groupkfold\u001b[39m\u001b[34m(df, feature_cols, label_col, group_col, model_names, n_splits, seed, proba_threshold)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fold_idx, (train_idx, test_idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(gkf.split(X, y, groups=groups)):\n\u001b[32m    195\u001b[39m     model = _make_model(model_name, random_state=seed + fold_idx)\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[33m\"\u001b[39m\u001b[33mpredict_proba\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    199\u001b[39m         proba = model.predict_proba(X[test_idx])[:, \u001b[32m1\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Julian\\OneDrive\\Desktop\\testing-retina-project\\.venv\\Lib\\site-packages\\xgboost\\core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Julian\\OneDrive\\Desktop\\testing-retina-project\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:1808\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1788\u001b[39m evals_result: EvalsLog = {}\n\u001b[32m   1789\u001b[39m train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[32m   1790\u001b[39m     missing=\u001b[38;5;28mself\u001b[39m.missing,\n\u001b[32m   1791\u001b[39m     X=X,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1805\u001b[39m     feature_types=feature_types,\n\u001b[32m   1806\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1808\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1809\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1810\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1811\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1812\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1813\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1814\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1815\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1816\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1817\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1818\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1819\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1820\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1822\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n\u001b[32m   1823\u001b[39m     \u001b[38;5;28mself\u001b[39m.objective = params[\u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Julian\\OneDrive\\Desktop\\testing-retina-project\\.venv\\Lib\\site-packages\\xgboost\\core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Julian\\OneDrive\\Desktop\\testing-retina-project\\.venv\\Lib\\site-packages\\xgboost\\training.py:199\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Julian\\OneDrive\\Desktop\\testing-retina-project\\.venv\\Lib\\site-packages\\xgboost\\core.py:2434\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2430\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2433\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2434\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2435\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2436\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2437\u001b[39m     )\n\u001b[32m   2438\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2439\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# --- Proper models (GroupKFold by patient) ---\n",
        "import importlib\n",
        "\n",
        "import src.retina_evaluation as reval\n",
        "\n",
        "importlib.reload(reval)\n",
        "\n",
        "# Choose which tasks to run\n",
        "TASKS = [\"task_any_dr\", \"task_referable\"]  # add \"task_3class\" later\n",
        "MODELS = [\"logreg\", \"rf\", \"mlp\", \"xgb\", \"lgbm\"]\n",
        "\n",
        "all_summaries = []\n",
        "all_oof = []\n",
        "\n",
        "for task in TASKS:\n",
        "    res = reval.evaluate_binary_models_groupkfold(\n",
        "        df=df,\n",
        "        feature_cols=ds.feature_cols,\n",
        "        label_col=task,\n",
        "        group_col=\"patient_id\",\n",
        "        model_names=MODELS,\n",
        "        n_splits=5,\n",
        "        seed=0,\n",
        "    )\n",
        "    s = res.summary.copy()\n",
        "    s.insert(0, \"task\", task)\n",
        "    all_summaries.append(s)\n",
        "    all_oof.append(res.oof)\n",
        "\n",
        "summary_df = pd.concat(all_summaries, ignore_index=True)\n",
        "oof_df = pd.concat(all_oof, ignore_index=True)\n",
        "\n",
        "print(\"\\n=== Cross-validated summary (patient-level GroupKFold) ===\")\n",
        "display(summary_df)\n",
        "\n",
        "# --- Fairness / subgroup slices (sex + age bins) ---\n",
        "# Uses out-of-fold predictions so we slice metrics on held-out data.\n",
        "for task in TASKS:\n",
        "    print(f\"\\n=== Subgroup report for: {task} ===\")\n",
        "    task_oof = oof_df[oof_df[\"label_col\"] == task]\n",
        "\n",
        "    # Pick best model by roc_auc_mean (fallback to first if all NaN)\n",
        "    best = (\n",
        "        summary_df[summary_df[\"task\"] == task]\n",
        "        .sort_values(by=\"roc_auc_mean\", ascending=False, na_position=\"last\")\n",
        "        .iloc[0][\"model\"]\n",
        "    )\n",
        "    print(\"Best model:\", best)\n",
        "\n",
        "    if \"sex\" in task_oof.columns and task_oof[\"sex\"].notna().any():\n",
        "        sex_report = reval.fairness_report_binary(oof=task_oof, model_name=best, by=\"sex\")\n",
        "        print(\"\\nBy sex:\")\n",
        "        display(sex_report)\n",
        "\n",
        "    if \"age\" in task_oof.columns and task_oof[\"age\"].notna().any():\n",
        "        age_report = reval.fairness_report_binary(oof=task_oof, model_name=best, by=\"age_bin\")\n",
        "        print(\"\\nBy age_bin (<40 / 40-60 / >60):\")\n",
        "        display(age_report)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.13.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
